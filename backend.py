import time, io, os, shutil, logging
from fastapi import FastAPI, HTTPException, UploadFile, File, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, JSONResponse
from typing import Optional, List
from pydantic import BaseModel
import fitz  # PyMuPDF
from PIL import Image
from openai import OpenAI
import sqlite3
import datetime
import hashlib
from concurrent.futures import ThreadPoolExecutor, as_completed
from db import init_db, save_payslip, get_payslip, latest_payslip_id, list_payslips

logging.basicConfig(level=logging.INFO)
log = logging.getLogger("payslip")

try:
    import pytesseract

    def _detect_tess():
        path = shutil.which("tesseract")
        ver = str(pytesseract.get_tesseract_version()) if path else None
        langs = pytesseract.get_languages(config="") if path else []
        return path, ver, langs

    TESSERACT_PATH, TESSERACT_VERSION, TESSERACT_LANGS = _detect_tess()
except Exception:
    pytesseract = None
    TESSERACT_PATH, TESSERACT_VERSION, TESSERACT_LANGS = None, None, []

TESSERACT_AVAILABLE = TESSERACT_PATH is not None

# OCR budgets to avoid long hangs
MAX_OCR_PAGES = int(os.getenv("MAX_OCR_PAGES", "3"))
MAX_TOTAL_SECONDS = int(os.getenv("MAX_TOTAL_SECONDS", "60"))
MAX_BYTES = 8 * 1024 * 1024  # 8MB

# Rasterization/OCR tuning
# Increase default scale to improve OCR accuracy on small Hebrew text.
# Can be overridden with OCR_SCALE env variable if needed.
SCALE = float(os.getenv("OCR_SCALE", "3.0"))  # higher for better accuracy
MATRIX = fitz.Matrix(SCALE, SCALE)
USE_LANG = "heb+eng"  # will auto-fallback below
OCR_CONFIG = "--oem 3 --psm 6"  # balance speed and accuracy
MAX_OCR_WORKERS = int(os.getenv("MAX_OCR_WORKERS", "4"))


def ocr_image_fast(pil_img):
    """Run tesseract OCR with language fallback."""
    if not TESSERACT_AVAILABLE:
        raise HTTPException(status_code=400, detail="OCR is not available on server")
    lang = USE_LANG if "heb" in TESSERACT_LANGS else "eng"
    try:
        return pytesseract.image_to_string(
            pil_img.convert("L"), lang=lang, config=OCR_CONFIG
        )
    except Exception:
        # last resort: let tesseract auto-detect
        return pytesseract.image_to_string(pil_img.convert("L"), config=OCR_CONFIG)
log.info(
    "Tesseract available=%s path=%s ver=%s langs_count=%d",
    TESSERACT_AVAILABLE,
    TESSERACT_PATH,
    TESSERACT_VERSION,
    len(TESSERACT_LANGS),
)

if not os.getenv("OPENAI_API_KEY"):
    # Do not raise immediately on import if you prefer; you can check inside the handler instead.
    pass

app = FastAPI()

# Initialize simple payslip memory database
init_db()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/healthz")
async def healthz():
    return {
        "status": "ok",
        "ocr": {
            "available": TESSERACT_AVAILABLE,
            "version": TESSERACT_VERSION,
            "langs_count": len(TESSERACT_LANGS),
        },
    }


@app.get("/debug/ocr")
async def debug_ocr():
    return {
        "available": TESSERACT_AVAILABLE,
        "path": TESSERACT_PATH,
        "version": TESSERACT_VERSION,
        "langs": TESSERACT_LANGS,
    }


@app.get("/", response_class=HTMLResponse)
async def read_frontend():
    with open("frontend.html", "r", encoding="utf-8") as f:
        return HTMLResponse(content=f.read())

# Knowledge base content
KNOWLEDGE_BASE = """
# ğŸ§  Knowledge Base: × ×™×ª×•×— ×ª×œ×•×©×™ ×©×›×¨

××“×¨×™×š ××œ× ×•××¢××™×§ ×¢×œ ××™×š ×œ×§×¨×•×, ×œ×”×‘×™×Ÿ ×•×œ× ×ª×— ×ª×œ×•×©×™ ×©×›×¨, ×›×•×œ×œ ×”×’×“×¨×•×ª, ×¨×›×™×‘×™ ×”×ª×œ×•×©, × ×™×›×•×™×™×, ×¤× ×¡×™×”, ×•×”×¡×‘×¨×™× ×—×©×•×‘×™×.

## ğŸ“Œ 1. ×¤×¨×˜×™ ×”×¢×•×‘×“ ×•×”××¢×‘×™×“
- ×©× ×”×¢×•×‘×“/×ª ×•×ª×¢×•×“×ª ×–×”×•×ª
- ×©× ×”×¢×¡×§, ××¡' ×ª×™×§ × ×™×›×•×™×™×, ×›×ª×•×‘×ª
- ×¡×•×’ ××©×¨×”, ×¡×˜×˜×•×¡ ××©×¤×—×ª×™, ×ª×•×©×‘ ×™×©×¨××œ?
- ×ª××¨×™×š ×ª×—×™×œ×ª ×¢×‘×•×“×” ×•×•×ª×§
- ×”×× ××©×¨×” ×™×—×™×“×” ××• × ×•×¡×¤×ª
- ×¡×•×’ ×©×›×¨: ×—×•×“×©×™ ××• ×©×¢×ª×™

## ğŸ’¸ 2. ×ª×©×œ×•××™× ×•×”×—×–×¨×™ ×”×•×¦××•×ª

### â¤ ×ª×©×œ×•××™× ×‘×©×œ ×¢×‘×•×“×”:
- ×©×›×¨ ×‘×¡×™×¡, ×©×¢×•×ª × ×•×¡×¤×•×ª, ×¢××œ×•×ª ××›×™×¨×”

### â¤ ×–×›×•×™×•×ª ×¡×•×¦×™××œ×™×•×ª:
- ×“××™ ×”×‘×¨××”, ×—×’×™×, ××™×œ×•××™×, ×™××™ ××—×œ×”, ×—×•×¤×©×” ×‘×ª×©×œ×•×, ×‘×™×“×•×“

### â¤ ×”×—×–×¨×™ ×”×•×¦××•×ª:
- × ×¡×™×¢×•×ª, ×˜×œ×¤×•×Ÿ, ××¨×•×—×•×ª, ×©×•×•×™ ××ª× ×•×ª (×œ××©×œ ×ª×œ×•×©×™× ×œ×—×’)

## ğŸš« 3. × ×™×›×•×™×™ ×—×•×‘×”
- ××¡ ×”×›× ×¡×”
- ×‘×™×˜×•×— ×œ××•××™
- ×‘×™×˜×•×— ×‘×¨×™××•×ª
- ×¤× ×¡×™×”
- ×“××™ ×˜×™×¤×•×œ ×œ××¨×’×•×Ÿ ××§×¦×•×¢×™ (0.8% ×× ×™×© ×”×¡×›×)

### ğŸ’¡ ×—×©×•×‘:
×”××¢×¡×™×§ ××—×•×™×‘ ×œ× ×›×•×ª ×•×œ×”×¢×‘×™×¨ ×ª×©×œ×•××™× ××œ×• ×¢×œ ×¤×™ ×—×•×§. ××™ × ×™×›×•×™/××™ ×“×™×•×•×— = ×¢×‘×™×¨×” ×¤×œ×™×œ×™×ª.

## ğŸ’¼ 4. × ×™×›×•×™×™ ×¨×©×•×ª
- ×§×¨×Ÿ ×”×©×ª×œ××•×ª
- ××¨×•×—×•×ª ××¡×•×‘×¡×“×•×ª, ×§× ×™×•×ª ×‘×”× ×—×”
- ××§×“××•×ª/×—×•×‘×•×ª
- ×§× ×¡×•×ª (×¨×§ ×× ××•×©×¨×• ×‘×—×•×§ ××• ×”×¡×›×)

## ğŸ§® 5. ×—×™×©×•×‘ ×”×¤×¨×©×•×ª ×œ×¤× ×¡×™×”

### â¤ ×©×™×¢×•×¨×™ ×”×¤×¨×©×”:
- ××¢×¡×™×§: 6.5%
- ×¢×•×‘×“: 6%
- ×œ×¤×™×¦×•×™×™×: ×œ×¤×—×•×ª 6%

### â¤ ×¨×›×™×‘×™× ×œ×—×™×©×•×‘ ×¤× ×¡×™×”:
- ×©×›×¨ ×‘×¡×™×¡ + ×ª×•×¡×¤×•×ª ×§×‘×•×¢×•×ª
- ×©×¢×•×ª ×¨×’×™×œ×•×ª
- ×“××™ ×—×•×¤×©×”, ××—×œ×”, ×‘×™×“×•×“, ×—×’×™×, ×‘×•× ×•×¡×™× ×§×‘×•×¢×™×

> ×©×¢×•×ª × ×•×¡×¤×•×ª *×œ×* × ×›×œ×œ×•×ª ××œ× ×× ×›×Ÿ × ×§×‘×¢ ××—×¨×ª.

## ğŸ—“ï¸ 6. ××™×“×¢ × ×•×¡×£ ×‘×ª×œ×•×©
- ××¡×¤×¨ ×™××™ ×¢×‘×•×“×” / ×©×¢×•×ª / ×—×•×¤×©×•×ª
- × ×§×•×“×•×ª ×–×™×›×•×™: 2.25 ×œ×’×‘×¨ ×ª×•×©×‘ ×™×©×¨××œ, 2.75 ×œ××™×©×”
- ×¡×›×•××™ ×ª×©×œ×•× ×œ×‘×™×˜×•×— ×œ××•××™, ×‘×¨×™××•×ª ×•××¡ ×”×›× ×¡×”

## ğŸ“Š 7. × ×ª×•× ×™× ××¦×˜×‘×¨×™×
- ×©×›×¨ ××¦×˜×‘×¨ ×œ×©× ×”
- ×¡×”"×› ××¡×™× ×©×©×•×œ××•
- ×”×¤×¨×©×•×ª ×œ×¤× ×¡×™×”
- ×¡×›×•××™ ×—×•×¤×©×” ×•××—×œ×” ×©× ×¦×‘×¨×•/× ×•×¦×œ×•

## ğŸ˜· 8. ×—×•×¤×©×” ×•××—×œ×”
- ×™××™ ×—×•×¤×©×” ×©× ×¦×‘×¨×• ×”×—×•×“×© / × ×•×¦×œ×•
- ×™××™ ××—×œ×” ×©× ×¦×‘×¨×• / × ×•×¦×œ×•
- ×—×©×•×‘ ×œ××¢×§×‘ ××©×¤×˜×™ (×¤×™×¦×•×™×™×, ×–×›×•×™×•×ª ×¡×•×¦×™××œ×™×•×ª)

## âš ï¸ 9. ×“×’×©×™× ×—×©×•×‘×™×
- ×—×•×‘×” ×¢×œ ×”××¢×¡×™×§ ×œ××¡×•×¨ ×ª×œ×•×© ×©×›×¨ ×‘×›×œ ×—×•×“×©
- ×—×•×‘×” ×œ×©××•×¨ ××ª ×”×ª×œ×•×©×™× (×”×•×›×—×” ×œ×–×›×•×™×•×ª)
- ×¢×‘×•×“×” "×‘×©×—×•×¨" ××¡×›× ×ª ××ª ×”×¢×•×‘×“, ××™×Ÿ ×–×›×•×™×•×ª
"""

# Configure OpenAI/Groq API
def setup_api():
    """Setup OpenAI client for Groq API"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise HTTPException(status_code=500, detail="OPENAI_API_KEY is not set")
    client = OpenAI(
        api_key=api_key,
        base_url="https://api.groq.com/openai/v1"
    )
    return client

# Database functions
def init_database():
    """Initialize SQLite database for user data"""
    conn = sqlite3.connect('payslip_data.db')
    cursor = conn.cursor()
    
    # Create users table
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS users (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id TEXT UNIQUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # Create payslips table
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS payslips (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id TEXT,
            filename TEXT,
            file_hash TEXT,
            extracted_text TEXT,
            ai_analysis TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (user_id) REFERENCES users (user_id)
        )
    ''')
    
    conn.commit()
    conn.close()

def save_payslip_analysis(user_id, filename, file_hash, extracted_text, ai_analysis):
    """Save payslip analysis to database"""
    conn = sqlite3.connect('payslip_data.db')
    cursor = conn.cursor()
    cursor.execute('''
        INSERT INTO payslips (user_id, filename, file_hash, extracted_text, ai_analysis)
        VALUES (?, ?, ?, ?, ?)
    ''', (user_id, filename, file_hash, extracted_text, ai_analysis))
    payslip_id = cursor.lastrowid
    conn.commit()
    conn.close()
    return payslip_id

def get_user_payslips(user_id):
    """Get all payslips for a user"""
    conn = sqlite3.connect('payslip_data.db')
    cursor = conn.cursor()
    cursor.execute('''
        SELECT id, filename, created_at, extracted_text, ai_analysis
        FROM payslips 
        WHERE user_id = ? 
        ORDER BY created_at DESC
        LIMIT 10
    ''', (user_id,))
    results = cursor.fetchall()
    conn.close()
    return results

def calculate_file_hash(file_content):
    """Calculate hash of file content"""
    return hashlib.md5(file_content).hexdigest()

def _ocr_bytes(img_bytes: bytes) -> str:
    """Run OCR on image bytes with basic orientation handling.

    Tries multiple rotations (0/90/180/270) and picks the longest result
    to handle scans that are saved sideways.
    """
    img = Image.open(io.BytesIO(img_bytes))
    best = ""
    for angle in (0, 90, 180, 270):
        rotated = img.rotate(angle, expand=True) if angle else img
        txt = (ocr_image_fast(rotated) or "").strip()
        if len(txt) > len(best):
            best = txt
        # If we already have some reasonable text, no need to try more rotations
        if len(best) > 20:
            break
    return best


def extract_text_from_pdf(pdf_content):
    """Extract text from PDF with time/page budgets and parallel OCR fallback."""
    start = time.perf_counter()
    ocr_pages_used = 0
    page_texts: List[str] = []
    try:
        with fitz.open(stream=pdf_content, filetype="pdf") as doc:
            page_count = doc.page_count
            images_for_ocr = {}
            for idx, page in enumerate(doc):
                if (time.perf_counter() - start) > MAX_TOTAL_SECONDS:
                    log.warning("OCR timeout budget hit at page %s", idx)
                    break
                direct = (page.get_text("text") or "").strip()
                if direct:
                    page_texts.append(direct)
                    continue
                if not TESSERACT_AVAILABLE:
                    raise HTTPException(
                        status_code=400,
                        detail=(
                            "PDF appears to be image-based but OCR is not available on server "
                            "(missing tesseract). Upload a text-based PDF or enable OCR."
                        ),
                    )
                if ocr_pages_used >= MAX_OCR_PAGES:
                    log.info(
                        "OCR page budget reached (%d). Skipping OCR for remaining pages.",
                        MAX_OCR_PAGES,
                    )
                    page_texts.append("")
                    continue
                pix = page.get_pixmap(matrix=MATRIX, alpha=False, colorspace=fitz.csGRAY)
                images_for_ocr[idx] = pix.tobytes("png")
                page_texts.append("")
                ocr_pages_used += 1

        if images_for_ocr:
            with ThreadPoolExecutor(max_workers=min(MAX_OCR_WORKERS, len(images_for_ocr))) as ex:
                future_map = {
                    ex.submit(_ocr_bytes, b): i for i, b in images_for_ocr.items()
                }
                for fut in as_completed(future_map):
                    idx = future_map[fut]
                    try:
                        page_texts[idx] = fut.result()
                    except Exception as e:
                        log.exception("OCR failed on page %s: %s", idx, e)

        full_text = "\n\n".join(t for t in page_texts if t).strip()
        elapsed = time.perf_counter() - start
        log.info(
            "Extracted %d chars using %d OCR pages in %.2fs (pages=%d)",
            len(full_text),
            ocr_pages_used,
            elapsed,
            page_count,
        )
        return full_text, ocr_pages_used, elapsed
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"PDF open failed: {str(e)[:200]}")

def extract_text_from_image(image_content):
    """Extract text from image using OCR with orientation handling."""
    if not TESSERACT_AVAILABLE:
        raise HTTPException(
            status_code=400,
            detail="OCR is not available on server (missing tesseract)",
        )
    try:
        return _ocr_bytes(image_content)
    except HTTPException:
        # Pass through HTTP errors raised by _ocr_bytes/ocr_image_fast
        raise
    except Exception:
        raise HTTPException(status_code=400, detail="×©×’×™××” ×‘-OCR ×©×œ ×”×ª××•× ×”.")

def explain_payslip_with_knowledge(text, client):
    """Get AI explanation of the payslip with knowledge base context"""
    try:
        messages = [
            {
                "role": "system", 
                "content": f"""××ª×” ××•××—×” ×œ×ª×œ×•×©×™ ×©×›×¨ ×‘×™×©×¨××œ ×¢× ×™×“×¢ ××¢××™×§ ×¢×œ ×”×—×•×§ ×”×™×©×¨××œ×™. 

{KNOWLEDGE_BASE}

×”×©×ª××© ×‘×™×“×¢ ×–×” ×›×“×™ ×œ×ª×ª ×”×¡×‘×¨ ××“×•×™×§, ××¤×•×¨×˜ ×•×‘×¨×•×¨ ×¢×œ ×ª×œ×•×© ×”×©×›×¨. 
×”×¡×‘×¨ ××ª ×”××©××¢×•×ª ×©×œ ×›×œ × ×™×›×•×™, ×ª×•×¡×¤×ª ×•××¡ ×‘×”×ª×‘×¡×¡ ×¢×œ ×”×—×•×§ ×”×™×©×¨××œ×™.
×”×©×ª××© ×‘×¢×‘×¨×™×ª ×¤×©×•×˜×” ×•×‘×¨×•×¨×”."""
            },
            {
                "role": "user", 
                "content": f"""×”× ×” ×ª×•×›×Ÿ ×”×ª×œ×•×© ×©×œ×™:

{text}

×× × ×”×¡×‘×¨ ×œ×™ ×‘×¤×™×¨×•×˜:
1. ××” ×”××©×›×•×¨×ª ×”×’×•×œ××™×ª ×©×œ×™?
2. ××™×œ×• × ×™×›×•×™×™× × ×¢×©×• ×•××” ×”××©××¢×•×ª ×©×œ×”×?
3. ××” ×”××©×›×•×¨×ª ×”× ×§×™×™×” ×©×œ×™?
4. ×”×× ×™×© ×ª×•×¡×¤×•×ª ××™×•×—×“×•×ª?
5. ×”×× ×”× ×™×›×•×™×™× × ×¨××™× ×ª×§×™× ×™× ×œ×¤×™ ×”×—×•×§?
6. ××™×–×” ×–×›×•×™×•×ª ×™×© ×œ×™ ×›×¢×•×‘×“?

×ª×Ÿ ×œ×™ ×”×¡×‘×¨ ××¤×•×¨×˜ ×•××•×‘×Ÿ ×‘×¢×‘×¨×™×ª ×¢× ×”×ª×™×™×—×¡×•×ª ×œ×—×•×§ ×”×™×©×¨××œ×™."""
            }
        ]
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            temperature=0.3,
            max_tokens=3000
        )
        
        return response.choices[0].message.content
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"×©×’×™××” ×‘×§×‘×œ×ª ×”×¡×‘×¨ ××”×‘×™× ×” ×”××œ××›×•×ª×™×ª: {str(e)}")

def compare_payslips_with_ai(payslips_data, client):
    """Compare multiple payslips using AI with knowledge base"""
    try:
        # Prepare payslips text for comparison
        payslips_text = ""
        for i, payslip in enumerate(payslips_data):
            payslips_text += f"=== ×ª×œ×•×© {i+1}: {payslip['filename']} ===\n{payslip['extracted_text']}\n\n"
        
        messages = [
            {
                "role": "system", 
                "content": f"""××ª×” ××•××—×” ×œ×ª×œ×•×©×™ ×©×›×¨ ×‘×™×©×¨××œ ×¢× ×™×“×¢ ××¢××™×§ ×¢×œ ×”×—×•×§ ×”×™×©×¨××œ×™.

{KNOWLEDGE_BASE}

×ª×¤×§×™×“×š ×œ×‘×¦×¢ ×”×©×•×•××” ××¤×•×¨×˜×ª ×‘×™×Ÿ ×ª×œ×•×©×™ ×©×›×¨ ×•×œ×”×ª×¨×™×¢ ×¢×œ:
1. ×”×‘×“×œ×™× ×‘×©×›×¨ ×•×ª×•×¡×¤×•×ª
2. ×©×™× ×•×™×™× ×‘× ×™×›×•×™×™×
3. ×©×’×™××•×ª ××• ××™-×”×ª×××•×ª ×œ×—×•×§
4. ××’××•×ª ×•×”×ª×¤×ª×—×•×™×•×ª
5. ×”××œ×¦×•×ª ×œ×¢×•×‘×“

×ª×Ÿ × ×™×ª×•×— ××¤×•×¨×˜ ×•××§×¦×•×¢×™ ×‘×¢×‘×¨×™×ª ×¤×©×•×˜×”."""
            },
            {
                "role": "user", 
                "content": f"""×× × ×”×©×•×•×” ×‘×™×Ÿ ×”×ª×œ×•×©×™× ×”×‘××™× ×•×ª×Ÿ × ×™×ª×•×— ××¤×•×¨×˜:

{payslips_text}

×× ×™ ××¢×•× ×™×™×Ÿ ×œ×§×‘×œ:
1. ×˜×‘×œ×ª ×”×©×•×•××” ×©×œ ×”×¡×›×•××™× ×”×¢×™×§×¨×™×™×
2. × ×™×ª×•×— ×”×”×‘×“×œ×™× ×•×”×¡×™×‘×•×ª ×”××¤×©×¨×™×•×ª
3. ×”×× ×™×© ×‘×¢×™×•×ª ××• ×©×’×™××•×ª
4. ××’××•×ª ×©×›×“××™ ×œ×©×™× ×œ×‘ ××œ×™×”×Ÿ
5. ×”××œ×¦×•×ª ×•×”×¢×¨×•×ª ×—×©×•×‘×•×ª

×ª×Ÿ ×ª×©×•×‘×” ×××•×¨×’× ×ª ×•××•×‘× ×ª ×‘×¢×‘×¨×™×ª."""
            }
        ]
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            temperature=0.3,
            max_tokens=4000
        )
        
        return response.choices[0].message.content
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"×©×’×™××” ×‘×”×©×•×•××ª ×ª×œ×•×©×™×: {str(e)}")

def answer_question_with_context(question, context, previous_analysis, client):
    """Answer user question with payslip context and knowledge base"""
    try:
        messages = [
            {
                "role": "system", 
                "content": f"""××ª×” ××•××—×” ×œ×ª×œ×•×©×™ ×©×›×¨ ×‘×™×©×¨××œ ×¢× ×™×“×¢ ××¢××™×§ ×¢×œ ×”×—×•×§ ×”×™×©×¨××œ×™.

{KNOWLEDGE_BASE}

×¢× ×” ×¢×œ ×©××œ×•×ª ×”××©×ª××© ×‘×”×ª×‘×¡×¡ ×¢×œ:
1. ×”×§×•× ×˜×§×¡×˜ ×©×œ ×ª×œ×•×© ×”×©×›×¨ ×©×œ×•
2. ×”×™×“×¢ ×”××§×¦×•×¢×™ ×¢×œ ×”×—×•×§ ×”×™×©×¨××œ×™
3. ×”× ×™×ª×•×— ×”×§×•×“× ×©× ×¢×©×”

×ª×Ÿ ×ª×©×•×‘×•×ª ××“×•×™×§×•×ª ×•××•×¢×™×œ×•×ª ×‘×¢×‘×¨×™×ª ×¤×©×•×˜×”."""
            },
            {
                "role": "user", 
                "content": f"""×ª×•×›×Ÿ ×ª×œ×•×© ×”×©×›×¨:
{context}

× ×™×ª×•×— ×§×•×“×:
{previous_analysis}

×”×©××œ×” ×©×œ×™:
{question}

×× × ×¢× ×” ×‘×”×ª×‘×¡×¡ ×¢×œ ×”××™×“×¢ ×”×§×™×™× ×•×”×™×“×¢ ×”××§×¦×•×¢×™ ×©×œ×š."""
            }
        ]
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            temperature=0.3,
            max_tokens=2000
        )
        
        return response.choices[0].message.content
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"×©×’×™××” ×‘×§×‘×œ×ª ×ª×©×•×‘×”: {str(e)}")

# Pydantic models
# Setup AI client for other endpoints
client = setup_api()

@app.post("/analyze-payslip")
async def analyze_payslip(file: UploadFile = File(...)):
    data = await file.read()
    if not data:
        raise HTTPException(status_code=400, detail="Uploaded file is empty")

    if len(data) > MAX_BYTES:
        raise HTTPException(status_code=400, detail="×”×§×•×‘×¥ ×’×“×•×œ ××“×™ (××¢×œ 8MB). × ×¡×” ×§×•×‘×¥ ×§×˜×Ÿ ×™×•×ª×¨.")

    log.info(
        "Analyze request: filename=%s content-type=%s size=%s",
        file.filename,
        file.content_type,
        len(data),
    )

    ct = (file.content_type or "").lower()
    is_pdf = ct in [
        "application/pdf",
        "application/x-pdf",
        "application/octet-stream",
    ] or file.filename.lower().endswith(".pdf")

    if is_pdf:
        full_text, ocr_pages_used, elapsed = extract_text_from_pdf(data)
    elif ct.startswith("image/"):
        start = time.perf_counter()
        full_text = extract_text_from_image(data)
        elapsed = time.perf_counter() - start
        ocr_pages_used = 1 if full_text else 0
    else:
        raise HTTPException(
            status_code=400,
            detail=f"Unsupported type '{ct}'. Upload PDF or image.",
        )

    if not full_text:
        raise HTTPException(
            status_code=400,
            detail="Couldn't extract text. Try a text-based PDF or increase OCR budget.",
        )

    meta = {"filename": file.filename, "size": len(data), "content_type": file.content_type}
    pid = save_payslip(full_text, meta)

    log.info(
        "Analyze done: chars=%d ocr_pages_used=%d elapsed=%.2fs",
        len(full_text),
        ocr_pages_used,
        elapsed,
    )

    return {
        "ok": True,
        "payslip_id": pid,
        "message": "×”×ª×œ×•×© × ×©××¨ ×‘×–×™×›×¨×•×Ÿ. ×¢×›×©×™×• ××¤×©×¨ ×œ×©××•×œ ×¢×œ×™×• ×©××œ×•×ª.",
    }


class AskBody(BaseModel):
    question: str
    payslip_id: str | None = None


@app.post("/ask", response_class=JSONResponse)
async def ask(body: AskBody):
    pid = body.payslip_id or latest_payslip_id()
    if not pid:
        raise HTTPException(status_code=400, detail="××™×Ÿ ×ª×œ×•×© ×©××•×¨. ×”×¢×œ×” ×ª×œ×•×© ×§×•×“×.")

    context = get_payslip(pid)
    if not context:
        raise HTTPException(status_code=404, detail="×ª×œ×•×© ×œ× × ××¦×.")

    try:
        from openai import OpenAI
        import os
        client = OpenAI(
            base_url="https://api.groq.com/openai/v1",
            api_key=os.getenv("OPENAI_API_KEY"),
        )
        system = (
            "You are an expert on Israeli payslips. Provide detailed, helpful answers in Hebrew. "
            "Explain the reasoning and break down relevant numbers."
        )
        messages = [
            {"role": "system", "content": system},
            {
                "role": "user",
                "content": f"××™×“×¢ ×ª×œ×•×©:\n{context}\n\n×©××œ×”:\n{body.question}",
            },
        ]
        resp = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            stream=False,
            timeout=60,
        )
        answer = resp.choices[0].message.content
    except Exception as e:
        raise HTTPException(status_code=502, detail=f"LLM error: {str(e)[:200]}")

    return {"ok": True, "payslip_id": pid, "answer": answer}


@app.get("/history", response_class=JSONResponse)
async def history():
    return {"ok": True, "items": list_payslips(20)}


@app.post("/debug/echo")
async def debug_echo(file: UploadFile = File(None)):
    return {
        "have_file": bool(file),
        "filename": getattr(file, "filename", None) if file else None,
        "content_type": getattr(file, "content_type", None) if file else None,
    }

@app.post("/compare-payslips")
async def compare_payslips(files: List[UploadFile] = File(...)):
    """Compare multiple payslip files"""
    if len(files) < 2:
        raise HTTPException(status_code=400, detail="× ×“×¨×©×™× ×œ×¤×—×•×ª 2 ×§×‘×¦×™× ×œ×”×©×•×•××”")
    
    if len(files) > 5:
        raise HTTPException(status_code=400, detail="× ×™×ª×Ÿ ×œ×”×©×•×•×ª ×¢×“ 5 ×ª×œ×•×©×™× ×‘×•-×–×× ×™×ª")
    
    payslips_data = []
    
    # Process each file
    for i, file in enumerate(files):
        # Read file content
        file_content = await file.read()
        
        # Extract text based on file type
        ct = (file.content_type or "").lower()
        is_pdf = ct in [
            "application/pdf",
            "application/x-pdf",
            "application/octet-stream",
        ] or file.filename.lower().endswith(".pdf")

        if is_pdf:
            extracted_text, _, _ = extract_text_from_pdf(file_content)
        elif ct.startswith("image/"):
            extracted_text = extract_text_from_image(file_content)
        else:
            raise HTTPException(status_code=400, detail=f"×§×•×‘×¥ {file.filename}: ×¡×•×’ ×§×•×‘×¥ ×œ× × ×ª××š")
        
        if not extracted_text or not extracted_text.strip():
            raise HTTPException(status_code=400, detail=f"×œ× ×”×¦×œ×—×ª×™ ×œ×—×œ×¥ ×˜×§×¡×˜ ××§×•×‘×¥ {file.filename}")
        
        payslips_data.append({
            "filename": file.filename,
            "extracted_text": extracted_text
        })
    
    # Get AI comparison analysis
    comparison_analysis = compare_payslips_with_ai(payslips_data, client)
    
    # Save comparison to database
    user_id = "web_user"
    for payslip in payslips_data:
        file_hash = calculate_file_hash(payslip["extracted_text"].encode())
        save_payslip_analysis(user_id, payslip["filename"], file_hash, 
                            payslip["extracted_text"], comparison_analysis)
    
    return {
        "success": True,
        "payslips": payslips_data,
        "comparison_analysis": comparison_analysis,
        "total_files": len(files)
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
