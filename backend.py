import time, os, logging
from fastapi import FastAPI, HTTPException, UploadFile, File, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, JSONResponse
from typing import Optional, List
from pydantic import BaseModel
import fitz  # PyMuPDF
from openai import OpenAI
import sqlite3
import datetime
import hashlib
from db import init_db, save_payslip, get_payslip, latest_payslip_id, list_payslips
from src.gemini_ocr import ocr_image_bytes

logging.basicConfig(level=logging.INFO)
log = logging.getLogger("payslip")

# OCR budgets to avoid long hangs
MAX_OCR_PAGES = int(os.getenv("MAX_OCR_PAGES", "3"))
MAX_TOTAL_SECONDS = int(os.getenv("MAX_TOTAL_SECONDS", "60"))
MAX_BYTES = 8 * 1024 * 1024  # 8MB

# Rasterization/OCR tuning
SCALE = float(os.getenv("OCR_SCALE", "3.0"))  # higher for better accuracy
MATRIX = fitz.Matrix(SCALE, SCALE)

if not os.getenv("OPENAI_API_KEY"):
    # Do not raise immediately on import if you prefer; you can check inside the handler instead.
    pass

app = FastAPI()

# Initialize simple payslip memory database
init_db()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/healthz")
async def healthz():
    return {"status": "ok", "ocr": "gemini"}


@app.get("/debug/ocr")
async def debug_ocr():
    return {"provider": "gemini", "model": os.getenv("GEMINI_MODEL", "gemini-2.5-flash")}


@app.get("/", response_class=HTMLResponse)
async def read_frontend():
    with open("frontend.html", "r", encoding="utf-8") as f:
        return HTMLResponse(content=f.read())

# Knowledge base content
KNOWLEDGE_BASE = """
# ğŸ§  Knowledge Base: × ×™×ª×•×— ×ª×œ×•×©×™ ×©×›×¨

××“×¨×™×š ××œ× ×•××¢××™×§ ×¢×œ ××™×š ×œ×§×¨×•×, ×œ×”×‘×™×Ÿ ×•×œ× ×ª×— ×ª×œ×•×©×™ ×©×›×¨, ×›×•×œ×œ ×”×’×“×¨×•×ª, ×¨×›×™×‘×™ ×”×ª×œ×•×©, × ×™×›×•×™×™×, ×¤× ×¡×™×”, ×•×”×¡×‘×¨×™× ×—×©×•×‘×™×.

## ğŸ“Œ 1. ×¤×¨×˜×™ ×”×¢×•×‘×“ ×•×”××¢×‘×™×“
- ×©× ×”×¢×•×‘×“/×ª ×•×ª×¢×•×“×ª ×–×”×•×ª
- ×©× ×”×¢×¡×§, ××¡' ×ª×™×§ × ×™×›×•×™×™×, ×›×ª×•×‘×ª
- ×¡×•×’ ××©×¨×”, ×¡×˜×˜×•×¡ ××©×¤×—×ª×™, ×ª×•×©×‘ ×™×©×¨××œ?
- ×ª××¨×™×š ×ª×—×™×œ×ª ×¢×‘×•×“×” ×•×•×ª×§
- ×”×× ××©×¨×” ×™×—×™×“×” ××• × ×•×¡×¤×ª
- ×¡×•×’ ×©×›×¨: ×—×•×“×©×™ ××• ×©×¢×ª×™

## ğŸ’¸ 2. ×ª×©×œ×•××™× ×•×”×—×–×¨×™ ×”×•×¦××•×ª

### â¤ ×ª×©×œ×•××™× ×‘×©×œ ×¢×‘×•×“×”:
- ×©×›×¨ ×‘×¡×™×¡, ×©×¢×•×ª × ×•×¡×¤×•×ª, ×¢××œ×•×ª ××›×™×¨×”

### â¤ ×–×›×•×™×•×ª ×¡×•×¦×™××œ×™×•×ª:
- ×“××™ ×”×‘×¨××”, ×—×’×™×, ××™×œ×•××™×, ×™××™ ××—×œ×”, ×—×•×¤×©×” ×‘×ª×©×œ×•×, ×‘×™×“×•×“

### â¤ ×”×—×–×¨×™ ×”×•×¦××•×ª:
- × ×¡×™×¢×•×ª, ×˜×œ×¤×•×Ÿ, ××¨×•×—×•×ª, ×©×•×•×™ ××ª× ×•×ª (×œ××©×œ ×ª×œ×•×©×™× ×œ×—×’)

## ğŸš« 3. × ×™×›×•×™×™ ×—×•×‘×”
- ××¡ ×”×›× ×¡×”
- ×‘×™×˜×•×— ×œ××•××™
- ×‘×™×˜×•×— ×‘×¨×™××•×ª
- ×¤× ×¡×™×”
- ×“××™ ×˜×™×¤×•×œ ×œ××¨×’×•×Ÿ ××§×¦×•×¢×™ (0.8% ×× ×™×© ×”×¡×›×)

### ğŸ’¡ ×—×©×•×‘:
×”××¢×¡×™×§ ××—×•×™×‘ ×œ× ×›×•×ª ×•×œ×”×¢×‘×™×¨ ×ª×©×œ×•××™× ××œ×• ×¢×œ ×¤×™ ×—×•×§. ××™ × ×™×›×•×™/××™ ×“×™×•×•×— = ×¢×‘×™×¨×” ×¤×œ×™×œ×™×ª.

## ğŸ’¼ 4. × ×™×›×•×™×™ ×¨×©×•×ª
- ×§×¨×Ÿ ×”×©×ª×œ××•×ª
- ××¨×•×—×•×ª ××¡×•×‘×¡×“×•×ª, ×§× ×™×•×ª ×‘×”× ×—×”
- ××§×“××•×ª/×—×•×‘×•×ª
- ×§× ×¡×•×ª (×¨×§ ×× ××•×©×¨×• ×‘×—×•×§ ××• ×”×¡×›×)

## ğŸ§® 5. ×—×™×©×•×‘ ×”×¤×¨×©×•×ª ×œ×¤× ×¡×™×”

### â¤ ×©×™×¢×•×¨×™ ×”×¤×¨×©×”:
- ××¢×¡×™×§: 6.5%
- ×¢×•×‘×“: 6%
- ×œ×¤×™×¦×•×™×™×: ×œ×¤×—×•×ª 6%

### â¤ ×¨×›×™×‘×™× ×œ×—×™×©×•×‘ ×¤× ×¡×™×”:
- ×©×›×¨ ×‘×¡×™×¡ + ×ª×•×¡×¤×•×ª ×§×‘×•×¢×•×ª
- ×©×¢×•×ª ×¨×’×™×œ×•×ª
- ×“××™ ×—×•×¤×©×”, ××—×œ×”, ×‘×™×“×•×“, ×—×’×™×, ×‘×•× ×•×¡×™× ×§×‘×•×¢×™×

> ×©×¢×•×ª × ×•×¡×¤×•×ª *×œ×* × ×›×œ×œ×•×ª ××œ× ×× ×›×Ÿ × ×§×‘×¢ ××—×¨×ª.

## ğŸ—“ï¸ 6. ××™×“×¢ × ×•×¡×£ ×‘×ª×œ×•×©
- ××¡×¤×¨ ×™××™ ×¢×‘×•×“×” / ×©×¢×•×ª / ×—×•×¤×©×•×ª
- × ×§×•×“×•×ª ×–×™×›×•×™: 2.25 ×œ×’×‘×¨ ×ª×•×©×‘ ×™×©×¨××œ, 2.75 ×œ××™×©×”
- ×¡×›×•××™ ×ª×©×œ×•× ×œ×‘×™×˜×•×— ×œ××•××™, ×‘×¨×™××•×ª ×•××¡ ×”×›× ×¡×”

## ğŸ“Š 7. × ×ª×•× ×™× ××¦×˜×‘×¨×™×
- ×©×›×¨ ××¦×˜×‘×¨ ×œ×©× ×”
- ×¡×”"×› ××¡×™× ×©×©×•×œ××•
- ×”×¤×¨×©×•×ª ×œ×¤× ×¡×™×”
- ×¡×›×•××™ ×—×•×¤×©×” ×•××—×œ×” ×©× ×¦×‘×¨×•/× ×•×¦×œ×•

## ğŸ˜· 8. ×—×•×¤×©×” ×•××—×œ×”
- ×™××™ ×—×•×¤×©×” ×©× ×¦×‘×¨×• ×”×—×•×“×© / × ×•×¦×œ×•
- ×™××™ ××—×œ×” ×©× ×¦×‘×¨×• / × ×•×¦×œ×•
- ×—×©×•×‘ ×œ××¢×§×‘ ××©×¤×˜×™ (×¤×™×¦×•×™×™×, ×–×›×•×™×•×ª ×¡×•×¦×™××œ×™×•×ª)

## âš ï¸ 9. ×“×’×©×™× ×—×©×•×‘×™×
- ×—×•×‘×” ×¢×œ ×”××¢×¡×™×§ ×œ××¡×•×¨ ×ª×œ×•×© ×©×›×¨ ×‘×›×œ ×—×•×“×©
- ×—×•×‘×” ×œ×©××•×¨ ××ª ×”×ª×œ×•×©×™× (×”×•×›×—×” ×œ×–×›×•×™×•×ª)
- ×¢×‘×•×“×” "×‘×©×—×•×¨" ××¡×›× ×ª ××ª ×”×¢×•×‘×“, ××™×Ÿ ×–×›×•×™×•×ª
"""

# Configure OpenAI/Groq API
def setup_api():
    """Setup OpenAI client for Groq API"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise HTTPException(status_code=500, detail="OPENAI_API_KEY is not set")
    client = OpenAI(
        api_key=api_key,
        base_url="https://api.groq.com/openai/v1"
    )
    return client

# Database functions
def init_database():
    """Initialize SQLite database for user data"""
    conn = sqlite3.connect('payslip_data.db')
    cursor = conn.cursor()
    
    # Create users table
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS users (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id TEXT UNIQUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # Create payslips table
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS payslips (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id TEXT,
            filename TEXT,
            file_hash TEXT,
            extracted_text TEXT,
            ai_analysis TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (user_id) REFERENCES users (user_id)
        )
    ''')
    
    conn.commit()
    conn.close()

def save_payslip_analysis(user_id, filename, file_hash, extracted_text, ai_analysis):
    """Save payslip analysis to database"""
    conn = sqlite3.connect('payslip_data.db')
    cursor = conn.cursor()
    cursor.execute('''
        INSERT INTO payslips (user_id, filename, file_hash, extracted_text, ai_analysis)
        VALUES (?, ?, ?, ?, ?)
    ''', (user_id, filename, file_hash, extracted_text, ai_analysis))
    payslip_id = cursor.lastrowid
    conn.commit()
    conn.close()
    return payslip_id

def get_user_payslips(user_id):
    """Get all payslips for a user"""
    conn = sqlite3.connect('payslip_data.db')
    cursor = conn.cursor()
    cursor.execute('''
        SELECT id, filename, created_at, extracted_text, ai_analysis
        FROM payslips 
        WHERE user_id = ? 
        ORDER BY created_at DESC
        LIMIT 10
    ''', (user_id,))
    results = cursor.fetchall()
    conn.close()
    return results

def calculate_file_hash(file_content):
    """Calculate hash of file content"""
    return hashlib.md5(file_content).hexdigest()

def _ocr_bytes(img_bytes: bytes) -> str:
    """Run OCR on image bytes via Gemini API."""
    return ocr_image_bytes(img_bytes)


def extract_text_from_pdf(pdf_content):
    """Extract text from PDF using Gemini OCR for image-only pages.

    If initial extraction returns no text (e.g. due to a very low OCR page budget),
    a second pass will OCR any skipped pages.
    """
    start = time.perf_counter()
    ocr_pages_used = 0
    page_texts: List[str] = []
    pending_ocr: List[tuple[int, bytes]] = []
    try:
        with fitz.open(stream=pdf_content, filetype="pdf") as doc:
            page_count = doc.page_count
            for idx, page in enumerate(doc):
                if (time.perf_counter() - start) > MAX_TOTAL_SECONDS:
                    log.warning("OCR timeout budget hit at page %s", idx)
                    break
                direct = (page.get_text("text") or "").strip()
                if direct:
                    page_texts.append(direct)
                    continue
                pix = page.get_pixmap(matrix=MATRIX, alpha=False, colorspace=fitz.csGRAY)
                if ocr_pages_used >= MAX_OCR_PAGES:
                    pending_ocr.append((idx, pix.tobytes("png")))
                    page_texts.append("")
                    continue
                text = _ocr_bytes(pix.tobytes("png"))
                page_texts.append(text)
                if text:
                    ocr_pages_used += 1

        full_text = "\n\n".join(t for t in page_texts if t).strip()

        if not full_text and pending_ocr:
            for idx, data in pending_ocr:
                if (time.perf_counter() - start) > MAX_TOTAL_SECONDS:
                    log.warning("OCR timeout during fallback at page %s", idx)
                    break
                text = _ocr_bytes(data)
                page_texts[idx] = text
                if text:
                    ocr_pages_used += 1
            full_text = "\n\n".join(t for t in page_texts if t).strip()

        elapsed = time.perf_counter() - start
        log.info(
            "Extracted %d chars using %d OCR pages in %.2fs (pages=%d)",
            len(full_text),
            ocr_pages_used,
            elapsed,
            page_count,
        )
        return full_text, ocr_pages_used, elapsed
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"PDF open failed: {str(e)[:200]}")

def extract_text_from_image(image_content):
    """Extract text from image using Gemini OCR."""
    try:
        return _ocr_bytes(image_content)
    except Exception:
        raise HTTPException(status_code=400, detail="×©×’×™××” ×‘-OCR ×©×œ ×”×ª××•× ×”.")

def explain_payslip_with_knowledge(text, client):
    """Get AI explanation of the payslip with knowledge base context"""
    try:
        messages = [
            {
                "role": "system", 
                "content": f"""××ª×” ××•××—×” ×œ×ª×œ×•×©×™ ×©×›×¨ ×‘×™×©×¨××œ ×¢× ×™×“×¢ ××¢××™×§ ×¢×œ ×”×—×•×§ ×”×™×©×¨××œ×™. 

{KNOWLEDGE_BASE}

×”×©×ª××© ×‘×™×“×¢ ×–×” ×›×“×™ ×œ×ª×ª ×”×¡×‘×¨ ××“×•×™×§, ××¤×•×¨×˜ ×•×‘×¨×•×¨ ×¢×œ ×ª×œ×•×© ×”×©×›×¨. 
×”×¡×‘×¨ ××ª ×”××©××¢×•×ª ×©×œ ×›×œ × ×™×›×•×™, ×ª×•×¡×¤×ª ×•××¡ ×‘×”×ª×‘×¡×¡ ×¢×œ ×”×—×•×§ ×”×™×©×¨××œ×™.
×”×©×ª××© ×‘×¢×‘×¨×™×ª ×¤×©×•×˜×” ×•×‘×¨×•×¨×”."""
            },
            {
                "role": "user", 
                "content": f"""×”× ×” ×ª×•×›×Ÿ ×”×ª×œ×•×© ×©×œ×™:

{text}

×× × ×”×¡×‘×¨ ×œ×™ ×‘×¤×™×¨×•×˜:
1. ××” ×”××©×›×•×¨×ª ×”×’×•×œ××™×ª ×©×œ×™?
2. ××™×œ×• × ×™×›×•×™×™× × ×¢×©×• ×•××” ×”××©××¢×•×ª ×©×œ×”×?
3. ××” ×”××©×›×•×¨×ª ×”× ×§×™×™×” ×©×œ×™?
4. ×”×× ×™×© ×ª×•×¡×¤×•×ª ××™×•×—×“×•×ª?
5. ×”×× ×”× ×™×›×•×™×™× × ×¨××™× ×ª×§×™× ×™× ×œ×¤×™ ×”×—×•×§?
6. ××™×–×” ×–×›×•×™×•×ª ×™×© ×œ×™ ×›×¢×•×‘×“?

×ª×Ÿ ×œ×™ ×”×¡×‘×¨ ××¤×•×¨×˜ ×•××•×‘×Ÿ ×‘×¢×‘×¨×™×ª ×¢× ×”×ª×™×™×—×¡×•×ª ×œ×—×•×§ ×”×™×©×¨××œ×™."""
            }
        ]
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            temperature=0.3,
            max_tokens=3000
        )
        
        return response.choices[0].message.content
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"×©×’×™××” ×‘×§×‘×œ×ª ×”×¡×‘×¨ ××”×‘×™× ×” ×”××œ××›×•×ª×™×ª: {str(e)}")

def compare_payslips_with_ai(payslips_data, client):
    """Compare multiple payslips using AI with knowledge base"""
    try:
        # Prepare payslips text for comparison
        payslips_text = ""
        for i, payslip in enumerate(payslips_data):
            payslips_text += f"=== ×ª×œ×•×© {i+1}: {payslip['filename']} ===\n{payslip['extracted_text']}\n\n"
        
        messages = [
            {
                "role": "system", 
                "content": f"""××ª×” ××•××—×” ×œ×ª×œ×•×©×™ ×©×›×¨ ×‘×™×©×¨××œ ×¢× ×™×“×¢ ××¢××™×§ ×¢×œ ×”×—×•×§ ×”×™×©×¨××œ×™.

{KNOWLEDGE_BASE}

×ª×¤×§×™×“×š ×œ×‘×¦×¢ ×”×©×•×•××” ××¤×•×¨×˜×ª ×‘×™×Ÿ ×ª×œ×•×©×™ ×©×›×¨ ×•×œ×”×ª×¨×™×¢ ×¢×œ:
1. ×”×‘×“×œ×™× ×‘×©×›×¨ ×•×ª×•×¡×¤×•×ª
2. ×©×™× ×•×™×™× ×‘× ×™×›×•×™×™×
3. ×©×’×™××•×ª ××• ××™-×”×ª×××•×ª ×œ×—×•×§
4. ××’××•×ª ×•×”×ª×¤×ª×—×•×™×•×ª
5. ×”××œ×¦×•×ª ×œ×¢×•×‘×“

×ª×Ÿ × ×™×ª×•×— ××¤×•×¨×˜ ×•××§×¦×•×¢×™ ×‘×¢×‘×¨×™×ª ×¤×©×•×˜×”."""
            },
            {
                "role": "user", 
                "content": f"""×× × ×”×©×•×•×” ×‘×™×Ÿ ×”×ª×œ×•×©×™× ×”×‘××™× ×•×ª×Ÿ × ×™×ª×•×— ××¤×•×¨×˜:

{payslips_text}

×× ×™ ××¢×•× ×™×™×Ÿ ×œ×§×‘×œ:
1. ×˜×‘×œ×ª ×”×©×•×•××” ×©×œ ×”×¡×›×•××™× ×”×¢×™×§×¨×™×™×
2. × ×™×ª×•×— ×”×”×‘×“×œ×™× ×•×”×¡×™×‘×•×ª ×”××¤×©×¨×™×•×ª
3. ×”×× ×™×© ×‘×¢×™×•×ª ××• ×©×’×™××•×ª
4. ××’××•×ª ×©×›×“××™ ×œ×©×™× ×œ×‘ ××œ×™×”×Ÿ
5. ×”××œ×¦×•×ª ×•×”×¢×¨×•×ª ×—×©×•×‘×•×ª

×ª×Ÿ ×ª×©×•×‘×” ×××•×¨×’× ×ª ×•××•×‘× ×ª ×‘×¢×‘×¨×™×ª."""
            }
        ]
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            temperature=0.3,
            max_tokens=4000
        )
        
        return response.choices[0].message.content
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"×©×’×™××” ×‘×”×©×•×•××ª ×ª×œ×•×©×™×: {str(e)}")

def answer_question_with_context(question, context, previous_analysis, client):
    """Answer user question with payslip context and knowledge base"""
    try:
        messages = [
            {
                "role": "system", 
                "content": f"""××ª×” ××•××—×” ×œ×ª×œ×•×©×™ ×©×›×¨ ×‘×™×©×¨××œ ×¢× ×™×“×¢ ××¢××™×§ ×¢×œ ×”×—×•×§ ×”×™×©×¨××œ×™.

{KNOWLEDGE_BASE}

×¢× ×” ×¢×œ ×©××œ×•×ª ×”××©×ª××© ×‘×”×ª×‘×¡×¡ ×¢×œ:
1. ×”×§×•× ×˜×§×¡×˜ ×©×œ ×ª×œ×•×© ×”×©×›×¨ ×©×œ×•
2. ×”×™×“×¢ ×”××§×¦×•×¢×™ ×¢×œ ×”×—×•×§ ×”×™×©×¨××œ×™
3. ×”× ×™×ª×•×— ×”×§×•×“× ×©× ×¢×©×”

×ª×Ÿ ×ª×©×•×‘×•×ª ××“×•×™×§×•×ª ×•××•×¢×™×œ×•×ª ×‘×¢×‘×¨×™×ª ×¤×©×•×˜×”."""
            },
            {
                "role": "user", 
                "content": f"""×ª×•×›×Ÿ ×ª×œ×•×© ×”×©×›×¨:
{context}

× ×™×ª×•×— ×§×•×“×:
{previous_analysis}

×”×©××œ×” ×©×œ×™:
{question}

×× × ×¢× ×” ×‘×”×ª×‘×¡×¡ ×¢×œ ×”××™×“×¢ ×”×§×™×™× ×•×”×™×“×¢ ×”××§×¦×•×¢×™ ×©×œ×š."""
            }
        ]
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            temperature=0.3,
            max_tokens=2000
        )
        
        return response.choices[0].message.content
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"×©×’×™××” ×‘×§×‘×œ×ª ×ª×©×•×‘×”: {str(e)}")

# Pydantic models
# Setup AI client for other endpoints
client = setup_api()

@app.post("/analyze-payslip")
async def analyze_payslip(file: UploadFile = File(...)):
    data = await file.read()
    if not data:
        raise HTTPException(status_code=400, detail="Uploaded file is empty")

    if len(data) > MAX_BYTES:
        raise HTTPException(status_code=400, detail="×”×§×•×‘×¥ ×’×“×•×œ ××“×™ (××¢×œ 8MB). × ×¡×” ×§×•×‘×¥ ×§×˜×Ÿ ×™×•×ª×¨.")

    log.info(
        "Analyze request: filename=%s content-type=%s size=%s",
        file.filename,
        file.content_type,
        len(data),
    )

    ct = (file.content_type or "").lower()
    is_pdf = ct in [
        "application/pdf",
        "application/x-pdf",
        "application/octet-stream",
    ] or file.filename.lower().endswith(".pdf")

    if is_pdf:
        full_text, ocr_pages_used, elapsed = extract_text_from_pdf(data)
    elif ct.startswith("image/"):
        start = time.perf_counter()
        full_text = extract_text_from_image(data)
        elapsed = time.perf_counter() - start
        ocr_pages_used = 1 if full_text else 0
    else:
        raise HTTPException(
            status_code=400,
            detail=f"Unsupported type '{ct}'. Upload PDF or image.",
        )

    if not full_text:
        raise HTTPException(
            status_code=400,
            detail="Couldn't extract text. Try a text-based PDF or increase OCR budget.",
        )

    meta = {"filename": file.filename, "size": len(data), "content_type": file.content_type}
    pid = save_payslip(full_text, meta)

    log.info(
        "Analyze done: chars=%d ocr_pages_used=%d elapsed=%.2fs",
        len(full_text),
        ocr_pages_used,
        elapsed,
    )

    return {
        "ok": True,
        "payslip_id": pid,
        "message": "×”×ª×œ×•×© × ×©××¨ ×‘×–×™×›×¨×•×Ÿ. ×¢×›×©×™×• ××¤×©×¨ ×œ×©××•×œ ×¢×œ×™×• ×©××œ×•×ª.",
    }


class AskBody(BaseModel):
    question: str
    payslip_id: str | None = None


@app.post("/ask", response_class=JSONResponse)
async def ask(body: AskBody):
    pid = body.payslip_id or latest_payslip_id()
    if not pid:
        raise HTTPException(status_code=400, detail="××™×Ÿ ×ª×œ×•×© ×©××•×¨. ×”×¢×œ×” ×ª×œ×•×© ×§×•×“×.")

    context = get_payslip(pid)
    if not context:
        raise HTTPException(status_code=404, detail="×ª×œ×•×© ×œ× × ××¦×.")

    try:
        from openai import OpenAI
        import os
        client = OpenAI(
            base_url="https://api.groq.com/openai/v1",
            api_key=os.getenv("OPENAI_API_KEY"),
        )
        system = (
            "You are an expert on Israeli payslips. Provide detailed, helpful answers in Hebrew. "
            "Explain the reasoning and break down relevant numbers."
        )
        messages = [
            {"role": "system", "content": system},
            {
                "role": "user",
                "content": f"××™×“×¢ ×ª×œ×•×©:\n{context}\n\n×©××œ×”:\n{body.question}",
            },
        ]
        resp = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            stream=False,
            timeout=60,
        )
        answer = resp.choices[0].message.content
    except Exception as e:
        raise HTTPException(status_code=502, detail=f"LLM error: {str(e)[:200]}")

    return {"ok": True, "payslip_id": pid, "answer": answer}


@app.get("/history", response_class=JSONResponse)
async def history():
    return {"ok": True, "items": list_payslips(20)}


@app.post("/debug/echo")
async def debug_echo(file: UploadFile = File(None)):
    return {
        "have_file": bool(file),
        "filename": getattr(file, "filename", None) if file else None,
        "content_type": getattr(file, "content_type", None) if file else None,
    }

@app.post("/compare-payslips")
async def compare_payslips(files: List[UploadFile] = File(...)):
    """Compare multiple payslip files"""
    if len(files) < 2:
        raise HTTPException(status_code=400, detail="× ×“×¨×©×™× ×œ×¤×—×•×ª 2 ×§×‘×¦×™× ×œ×”×©×•×•××”")
    
    if len(files) > 5:
        raise HTTPException(status_code=400, detail="× ×™×ª×Ÿ ×œ×”×©×•×•×ª ×¢×“ 5 ×ª×œ×•×©×™× ×‘×•-×–×× ×™×ª")
    
    payslips_data = []
    
    # Process each file
    for i, file in enumerate(files):
        # Read file content
        file_content = await file.read()
        
        # Extract text based on file type
        ct = (file.content_type or "").lower()
        is_pdf = ct in [
            "application/pdf",
            "application/x-pdf",
            "application/octet-stream",
        ] or file.filename.lower().endswith(".pdf")

        if is_pdf:
            extracted_text, _, _ = extract_text_from_pdf(file_content)
        elif ct.startswith("image/"):
            extracted_text = extract_text_from_image(file_content)
        else:
            raise HTTPException(status_code=400, detail=f"×§×•×‘×¥ {file.filename}: ×¡×•×’ ×§×•×‘×¥ ×œ× × ×ª××š")
        
        if not extracted_text or not extracted_text.strip():
            raise HTTPException(status_code=400, detail=f"×œ× ×”×¦×œ×—×ª×™ ×œ×—×œ×¥ ×˜×§×¡×˜ ××§×•×‘×¥ {file.filename}")
        
        payslips_data.append({
            "filename": file.filename,
            "extracted_text": extracted_text
        })
    
    # Get AI comparison analysis
    comparison_analysis = compare_payslips_with_ai(payslips_data, client)
    
    # Save comparison to database
    user_id = "web_user"
    for payslip in payslips_data:
        file_hash = calculate_file_hash(payslip["extracted_text"].encode())
        save_payslip_analysis(user_id, payslip["filename"], file_hash, 
                            payslip["extracted_text"], comparison_analysis)
    
    return {
        "success": True,
        "payslips": payslips_data,
        "comparison_analysis": comparison_analysis,
        "total_files": len(files)
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
